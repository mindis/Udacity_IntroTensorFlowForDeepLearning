{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "014_Time_Window.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEDhBBjiMXfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Education - Udacity \"Intro to TensorFlow for Deep Learning\"\n",
        "# Module: Time Window\n",
        "# REF: https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c04_time_windows.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPblHar2_lwQ",
        "colab_type": "code",
        "outputId": "40ee49c1-222a-459f-dc97-e2833591baa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Import packages.\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "\n",
        "# Using version 2.x of Tensorflow.\n",
        "try:\n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Tensorflow.\n",
        "import tensorflow as tf\n",
        "\n",
        "# Print Tensorflow version.\n",
        "print('TensorFlow Version:', tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensorFlow Version: 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coAx7AiaznED",
        "colab_type": "code",
        "outputId": "e8a824b1-eb5e-475c-c136-fcfb211056a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Create a generated data range.\n",
        "# Values [0, 10]\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Dataset\")\n",
        "print(\"--------------------\")\n",
        "for v in dataset:\n",
        "  print(v.numpy())\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Dataset\n",
            "--------------------\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ6PEwHT5yX9",
        "colab_type": "code",
        "outputId": "4c471bd5-d878-47ae-c008-844ea9c4dd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Create a window of the dataset.\n",
        "# Split into 5 values, with shifting of 1.\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1)\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Window of Dataset\")\n",
        "print(\"--------------------\")\n",
        "for w in dataset:\n",
        "  for v in w:\n",
        "    # Specify end to make it prints on the same line.\n",
        "    print(v.numpy(), end=\" \")\n",
        "  print()\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Window of Dataset\n",
            "--------------------\n",
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n",
            "6 7 8 9 \n",
            "7 8 9 \n",
            "8 9 \n",
            "9 \n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8-gZo5s6pEA",
        "colab_type": "code",
        "outputId": "9ab6a144-7157-4ebc-ca6d-bccecb4adf5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Create a window with same fixed size.\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Fixed Window Size\")\n",
        "print(\"--------------------\")\n",
        "for w in dataset:\n",
        "  for v in w:\n",
        "    # Specify end to make it prints on the same line.\n",
        "    print(v.numpy(), end=\" \")\n",
        "  print()\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Fixed Window Size\n",
            "--------------------\n",
            "0 1 2 3 4 \n",
            "1 2 3 4 5 \n",
            "2 3 4 5 6 \n",
            "3 4 5 6 7 \n",
            "4 5 6 7 8 \n",
            "5 6 7 8 9 \n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t7LTppR68kK",
        "colab_type": "code",
        "outputId": "b86b2e15-f522-4b5b-dff1-c9fe90f86077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Each batch of the window is a dataset, but we rather want\n",
        "# batches in form of regular tensor.\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "\n",
        "# The dataset contains a tensor with size of 5.\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Batch of Window\")\n",
        "print(\"--------------------\")\n",
        "for w in dataset:\n",
        "  print(w.numpy())\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Batch of Window\n",
            "--------------------\n",
            "[0 1 2 3 4]\n",
            "[1 2 3 4 5]\n",
            "[2 3 4 5 6]\n",
            "[3 4 5 6 7]\n",
            "[4 5 6 7 8]\n",
            "[5 6 7 8 9]\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0e6fLZR8HCM",
        "colab_type": "code",
        "outputId": "7374db12-a563-4f3a-9d6d-54623a361728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# For machine learning we want input data with respective label.\n",
        "# Here we use the first 4 values as inputs, and the last one as labels.\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "\n",
        "# The dataset contains a tensor with size of 5.\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "\n",
        "# The dataset contains arrays of inputs and repective labels.\n",
        "dataset = dataset.map(lambda window: (window[ : -1], window[-1 : ]))\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Arrays of Dataset\")\n",
        "print(\"--------------------\")\n",
        "for x, y in dataset:\n",
        "  print(x.numpy(), y.numpy())\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Arrays of Dataset\n",
            "--------------------\n",
            "[0 1 2 3] [4]\n",
            "[1 2 3 4] [5]\n",
            "[2 3 4 5] [6]\n",
            "[3 4 5 6] [7]\n",
            "[4 5 6 7] [8]\n",
            "[5 6 7 8] [9]\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wt-NGqD9A6A",
        "colab_type": "code",
        "outputId": "4805cdd7-6fcb-46e8-f3ff-2a6020d6731f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# We also want the input to be shuffled and identical distributed.\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "\n",
        "# The dataset contains a tensor with size of 5.\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "\n",
        "# The dataset contains arrays of inputs and repective labels.\n",
        "dataset = dataset.map(lambda window: (window[ : -1], window[-1 : ]))\n",
        "\n",
        "# Shuffle the dataset.\n",
        "dataset = dataset.shuffle(buffer_size = 10)\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Shuffled Dataset\")\n",
        "print(\"--------------------\")\n",
        "for x, y in dataset:\n",
        "  print(x.numpy(), y.numpy())\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Shuffled Dataset\n",
            "--------------------\n",
            "[5 6 7 8] [9]\n",
            "[2 3 4 5] [6]\n",
            "[1 2 3 4] [5]\n",
            "[4 5 6 7] [8]\n",
            "[3 4 5 6] [7]\n",
            "[0 1 2 3] [4]\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDENKLlt9el2",
        "colab_type": "code",
        "outputId": "f0d794e9-f92e-4d73-aa27-0e5acb56e948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# We want to split the dataset into batches, usually 32.\n",
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\n",
        "\n",
        "# The dataset contains a tensor with size of 5.\n",
        "dataset = dataset.flat_map(lambda window: window.batch(5))\n",
        "\n",
        "# The dataset contains arrays of inputs and repective labels.\n",
        "dataset = dataset.map(lambda window: (window[ : -1], window[-1 : ]))\n",
        "\n",
        "# Shuffle the dataset.\n",
        "dataset = dataset.shuffle(buffer_size = 10)\n",
        "\n",
        "# Create batches. The 'prefetch' indicates the Tensorflow will\n",
        "# fetch the data while working, so we always have data to use.\n",
        "dataset = dataset.batch(2).prefetch(1)\n",
        "\n",
        "print(\"--------------------\")\n",
        "print(\"- Batch of Dataset\")\n",
        "print(\"--------------------\")\n",
        "for x, y in dataset:\n",
        "  print(\"x:\", x.numpy())\n",
        "  print(\"y:\", y.numpy())\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Batch of Dataset\n",
            "--------------------\n",
            "x: [[0 1 2 3]\n",
            " [4 5 6 7]]\n",
            "y: [[4]\n",
            " [8]]\n",
            "x: [[5 6 7 8]\n",
            " [2 3 4 5]]\n",
            "y: [[9]\n",
            " [6]]\n",
            "x: [[3 4 5 6]\n",
            " [1 2 3 4]]\n",
            "y: [[7]\n",
            " [5]]\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydejjoDU-qJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1ee856f2-5c8a-4478-8361-fb699d8b5cd0"
      },
      "source": [
        "# Create a function for these steps.\n",
        "# This converts a time series into a dataset for machine learning.\n",
        "def window_dataset(series, window_size, batch_size = 32, shuffle_buffer = 1000):\n",
        "  # Create a dataset of tensors.\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "  # Drop remaining values so we get same size.\n",
        "  dataset = dataset.window(window_size + 1, shift = 1, drop_remainder = True)\n",
        "\n",
        "  # The dataset contains a tensor with size of 5.\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "\n",
        "  # Split into two arrays, one for inputs and one for labels.\n",
        "  dataset = dataset.map(lambda window: (window[ : -1], window[-1 : ]))\n",
        "\n",
        "  # Shuffle the dataset.\n",
        "  dataset = dataset.shuffle(shuffle_buffer)\n",
        "\n",
        "  # Create batches. The 'prefetch' indicates the Tensorflow will\n",
        "  # fetch the data while working, so we always have data to use.\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "dataset = window_dataset(np.arange(10), 4, 2, 10)\n",
        "print(\"--------------------\")\n",
        "print(\"- Dataset\")\n",
        "print(\"--------------------\")\n",
        "for x, y in dataset:\n",
        "  print(\"x:\", x.numpy())\n",
        "  print(\"y:\", y.numpy())\n",
        "print(\"--------------------\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "- Dataset\n",
            "--------------------\n",
            "x: [[0 1 2 3]\n",
            " [2 3 4 5]]\n",
            "y: [[4]\n",
            " [6]]\n",
            "x: [[5 6 7 8]\n",
            " [3 4 5 6]]\n",
            "y: [[9]\n",
            " [7]]\n",
            "x: [[4 5 6 7]\n",
            " [1 2 3 4]]\n",
            "y: [[8]\n",
            " [5]]\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}